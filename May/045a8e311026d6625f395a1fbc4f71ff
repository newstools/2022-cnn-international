(CNN Business)Tech platforms have struggled for years to stamp out videos of real-time massacres, such as those depicting the Christchurch shootings of 2019 and now a mass shooting in Buffalo, New York, which police say was a racially motivated hate crime. But a new state law shows how the tech industry could soon be pressured to do less, not more, in how it polices even ultra-violent content. Imagine if Saturday's livestreamed video of the attack in Buffalo were legally required to remain on social media. Imagine Facebook, Twitter and YouTube were forced to allow those gruesome images, or posts amplifying the suspect's racist ideologies, in between wedding photos and your aunt's tuna casserole recipe, with no way to block it. Imagine videos of murder and hateful speech being burned into your brain because the law requires platforms to host all content that isn't strictly illegal. A Texas law has made all of that an open possibility. The law in question, HB 20, restricts tech platforms' ability to moderate user-generated content. In the name of free speech, HB 20 prohibits social media companies from blocking, banning or demoting user posts or accounts, and enables Texans to sue the platforms if they believe they've been silenced. After a federal appeals court allowed the law to take effect last week, the Supreme Court is now poised to rule on whether the law violates tech platforms' First Amendment rights. The online broadcast of Saturday's horrific murder spree only emphasizes the enormous stakes underlying the looming Supreme Court decision. And it puts into stark perspective the policy battle that's playing out at the state, national and global levels about how — or whether — social media companies should moderate their platforms. After HB 20 went into effect last week, it raised a host of questions about how social media will function in Texas going forward. Could tech platforms have to offer Texas-specific versions of their sites? Will some platforms stop providing services in Texas altogether? What could social media content in Texas actually look like, without content moderation? The answers are still unclear. What seemed like a hypothetical on Wednesday suddenly became painfully real on Saturday as social media firms scrambled to respond to the shooting, which was initially livestreamed on the video platform Twitch. Although Twitch said it removed the livestream within two minutes, that didn't prevent the video from being copied and shared on other platforms. Social media companies including Facebook-parent Meta, Twitter, YouTube and Reddit have banned the video from their sites and are working to remove copies of it. But under the Texas law, taking those steps could expose the tech companies to costly litigation. The shooting offers a horrifying example of the dilemma and the challenges facing tech platforms in Texas and potentially across the nation if the Supreme Court backs the state's content moderation law. A ruling siding with Texas would also likely bolster Florida lawmakers, who, driven by their stated belief tech companies discriminate politically against conservatives, have passed similar legislation that is also tied up in the courts. And it would give a roadmap to other states wishing to erect moderation bans, as well. It amounts to a confused regulatory environment that has some state governments moving to require lax moderation while others, such as European policymakers, appear poised to impose tighter moderation standards. New uncertainties for tech platforms under Texas law If the Texas law is upheld, social media firms will face greater restrictions on how they moderate content. As HB 20 is written, platforms would become liable in the state for taking steps to "block, ban, remove, deplatform, demonetize, de-boost, restrict, deny equal access or visibility to, or otherwise discriminate against expression." The law is so new that there haven't been any suits filed yet over acts of alleged censorship. According to Evelyn Douek, a platform moderation expert at Columbia University's Knight First Amendment Institute, platforms could try to remove something like the Buffalo video under HB 20 and justify it on the grounds they are not censoring expression, just removing content. "It's not obvious to me that the Texas social media law would require platforms to carry the Buffalo shooting video," Douek said. But Jeff Kosseff, a law professor and platform moderation expert at the US Naval Academy, said the law is still ambiguous enough to create enormous uncertainty for social media companies. The platforms, he said, would likely face immense legal pressure not to remove graphically violent content, including material like the Buffalo video, because plaintiffs could still claim that removing the videos is itself a stifling of viewpoints under HB 20. Even the threat of such suits could be a disincentive to moderation. "Even if you just remove the video and you say, 'This video violates our policy,' you're still going to open the door to claims it was removed because it was posted by someone who has a particular viewpoint on things," Kosseff told CNN. Whether tech platforms are sued for removing the video or sued for removing a user's viewpoint surrounding the video, the result would be the same — a law that effectively floods digital spaces with violent content, according to Steve Vladeck, law professor at the University of Texas and a CNN legal analyst. "There's no question that the Buffalo shooting video drives home both the stakes of the HB 20 dispute and what's wrong with HB 20 itself," Vladeck told CNN. "If any Texas-based account reposted or rebroadcast the Twitch stream, taking that down would, on my reading, clearly violate HB 20. When you deprive social media platforms of the ability to moderate content, you are all but guaranteeing that they will be awash in violent, inappropriate, and otherwise objectionable posts." Beyond the graphic video itself, the Buffalo shooting also implicates the spread of hateful speech online like the kind found in the shooting suspect's 180-page document, such as racist conspiracy theories. This type of content would clearly be required to stay up under HB 20, legal experts agreed, because it expresses a clear viewpoint. "My biggest concern is really restricting the platforms' ability to remove these theories that drive violence," Kosseff said. A push to rethink content moderation Beyond what HB 20 requires of tech platforms, the Buffalo video also raises questions surrounding some voluntary proposals to relax content moderation standards, such as what billionaire Elon Musk has in mind for Twitter. Musk is currently seeking to purchase Twitter in a $44 billion deal, saying he intends to bring more free speech to the platform by easing Twitter's enforcement of content rules. How might a Musk-owned Twitter handle the Buffalo video? It's not immediately clear. Twitter declined to comment and Musk didn't immediately respond to a request for comment. Musk has said that under his ownership Twitter would be much more reluctant to remove content or to permanently ban individuals — and that he believes Twitter should allow all legal speech in the jurisdictions it operates. He has softened his stance in recent weeks, however, acknowledging at a Financial Times conference that he would likely place some limits on speech. "If there are tweets that are wrong and bad, those should be either deleted or made invisible, and a suspension, a temporary suspension, is appropriate," Musk said. He added: "If they say something that is illegal or otherwise just destructive to the world ... perhaps a timeout, a temporary suspension, or that particular tweet should be made invisible or have very limited traction." Musk has not said whether Twitter should consider something like the Buffalo video to be either "wrong and bad" or "destructive to the world." Should he conclude that it is, then his stance on the video could also risk running afoul of HB 20. The result would be a clash between two entities — Musk and the Texas government — that ostensibly share the same goal of allowing more content that social media platforms, at least today, widely agree is objectionable. The immediate reaction by major social platforms to remove the Buffalo video reflects an established consensus about how to handle livestreamed videos of violence, one informed by years of painful experience. But rather than affirming that consensus, recent developments could now fracture and muddy it, with important ramifications for all social media users. 